<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN" "http://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd">
<html xmlns="http://www.w3.org/1999/xhtml">
<head>
  <meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
  <meta http-equiv="Content-Style-Type" content="text/css" />
  <meta name="generator" content="pandoc" />
  <meta name="author" content="Théo Matussière" />
  <title> Émergence de phénomènes linguistiques par apprentissage par renforcement à plusieurs agents</title>
  <style type="text/css">code{white-space: pre;}</style>
</head>
<body style="max-width: 40em;margin: auto;">
<div id="header">
<h1 class="title"> Émergence de phénomènes linguistiques par apprentissage par renforcement à plusieurs agents</h1>
<h2 class="author">Théo Matussière</h2>
<h3 class="date">Novembre 2018</h3>
</div>
<p><strong>Mots-clés</strong>: évolution du langage , apprentissage par renforcement, syntaxe, phonologie, protocole de communication, compositionnalité</p>
<p>Depuis quelques années l’avènement de méthodes permettant d’associer des objets mathématiques bien connus (les vecteurs de <span class="math inline">$\mathbb R^d$</span>) à des mots, des phrases ou même des images permet des avancées scientifiques significatives dans de nombreux domaines. Ces nouvelles méthodes, connues du public sous le nom de <em>Deep Learning</em>, ou apprentissage profond, ont permis des améliorations majeures dans la plupart des tâches classiques du Traitement Automatique des Langues (TAL, ou <em>Natural Language Processing</em>, NLP en anglais) comme la traduction, la résolution de références, la reconnaissance d’entités nommées ou la modélisation du dialogue.</p>
<p>Ces méthodes sont motivées par une approche statistique du langage, en partie en raison de l’hypothèse distributionnelle qui infère le sens d’un mot en fonction des mots avec lesquels il apparait régulièrement. L’estimation de ces cooccurrences de mots entre eux est le ressort le plus courant pour développer ces méthodes, elle est permise par l’analyse de grands corpus de textes. Bien qu’elles obtiennent des succès indéniables, il existe un regain d’intérêt pour des modélisations du langage qui prennent en compte sa nature fondamentalement interactive. Cette initiative a obtenu des résultats intéressants par le passé, notamment au regard des questions sur l’apparition et les évolutions du langage et de ses phénomènes associés. Parmi ces résultats, on trouve notamment <span>kirby_cumulative_2008</span>, où les auteurs montrent la viabilité de leur méthode itérative qui aboutit à des phénomènes linguistiques émergents. D’autres travaux comme <span>steels_synthetic_1997</span> étayent la pertinence de cette approche. Plus récemment les avancées de l’apprentissage par renforcement (<em>Reinforcement Learning</em>, RL), qui ont permis la victoire de l’algorithme AlphaGo au jeu de Go en 2016 <span class="citation"></span>, ont été mobilisées pour simuler l’émergence de protocoles de communication entre agents au sein de jeux collaboratifs. Les résultats de ces expériences ne sont pour l’instant pas convaincants puisque les systèmes de communication qu’ils obtiennent ne sont pas proprement complexes, et assez éloignés de nos langages humains.</p>
<p>Néanmoins, cette direction est prometteuse puisque la puissance de modélisation que permettent les méthodes de RL autorise la complexification des environnements et des agents. Enrichir les environnements, complexifier les tâches et bénéficier d’agents plus pourrait permettre l’observation de langages plus complexes. Notre démarche s’inscrit dans la continuité de ces travaux récents que nous détaillons dans la suite. Nous exposons notamment l’originalité de notre approche et les expériences et réflexions que nous comptons mener, puis l’organisation logistique du travail à venir.</p>
<h1 id="objectifs-intentions">Objectifs &amp; intentions</h1>
<p>La question de l’origine de nos langages humains est une question centrale de la philosophie et des sciences en général. L’hypothèse d’une évolution graduelle de systèmes de communication semble aujourd’hui la plus probable, en opposition aux théories Chomskiennes d’une apparition soudaine du langage dû à une mutation génétique et la naissance soudaine de l’. L’investigation sur la nature de cette évolution, sur les trajectoires qu’ont pu emprunter les langues humaines pour arriver au niveau de complexité que nous leur connaissons est l’objet de différentes disciplines, parmi lesquelles les sciences cognitives, la psychologie et la philosophie. La richesse du travail effectué par les chercheurs de ces disciplines est mis en avant par une initiative portée par <span>roberts_chield</span> qui compile les avancées faites autour de cette question sous la forme d’un graphe de causalité entre cause supposées et phénomènes linguistiques résultants.</p>
<p>Nous proposons une lecture originale de cette question. La recherche d’invariants universels aux langages humains s’est souvent révélée infructueuse <span class="citation"></span>, ainsi nous prendrons comme dénominateur commun minimal aux langues humaines l’existence d’une syntaxe, autrement dit d’une forme de compositionnalité, i.e. de l’existence de mots <em>fonctions</em>. Notre postulat est que cette compositionnalité est une réponse optimale au problème de la communication <em>sous contraintes</em>. Si <span>roberts_chield</span> fournit de nombreuses pistes quant à l’établissement desdites contraintes, nous avons isolés cinq contraintes fondamentales qui feront l’objet de nos expériences :</p>
<table>
<tbody>
<tr class="odd">
<td align="left"><strong>Contrainte</strong></td>
<td align="left"><strong>Description</strong></td>
</tr>
<tr class="even">
<td align="left">Expressivité</td>
<td align="left">Capacité à décrire son environnement dans toutes ses potentialités.</td>
</tr>
<tr class="odd">
<td align="left">Concision</td>
<td align="left">Communiquer coûte de l’énergie.</td>
</tr>
<tr class="even">
<td align="left">Mémoire</td>
<td align="left">Le vocabulaire doit être fini.</td>
</tr>
<tr class="odd">
<td align="left">Simplicité</td>
<td align="left">Le langage doit avoir une complexité de Kolmogorov minimale.</td>
</tr>
<tr class="even">
<td align="left">Robustesse au bruit</td>
<td align="left">Le canal de communication n’est pas parfaite.</td>
</tr>
</tbody>
</table>
<p>L’idée originale étant qu’expressivité et concision sont des contraintes poussant dans des sens opposés et nécessitant la naissance d’un mécanisme comme celui de la compositionnalité. Les discussions successives avec les encadrants proposés pour cette thèse ont ensuite fait naitre la nécessité d’une perspective moins simpliste sur le nombre et la complexité des contraintes qui s’appliquent de fait à nos environnements.</p>
<p>Nos premières expériences construirons de façon incrémentale sur l’état de l’art afin d’y ajouter ces contraintes. La première contrainte que nous testerons est celle de l’ajout de bruit dans les canaux de communication, car elle est la plus facile d’accès. Elle est de plus motivée par des recherches antérieures sur les matrices de confusion entre consonnes pour des locuteurs d’une langue donnée <span>miller1955analysis</span>. L’idée étant d’imposer des perturbations similaires à celles que l’on peut trouver dans nos langues humaines (matrices quasi-symétriques et quasi-diagonales) lors de l’envoi des symboles disponibles aux agents. C’est à dire qu’une matrice aléatoire quasi-symétrique et quasi-diagonale <span class="math inline"><em>B</em></span> décidera <span class="math inline"><em>P</em>[<em>s</em><sub><em>j</em></sub> reçu | <em>s</em><sub><em>i</em></sub> envoyé] = <em>B</em><sub><em>i</em>, <em>j</em></sub></span>, influant par là l’utilisation ou non de certains symboles et favorisant la redondance selon l’importance du bruit introduit. L’hypothèse sous-jacente étant que la redondance est une propriété commune à nos langues humaines, et qu’elle participe de la complexité, et pourquoi pas ultimement de la compositionnalité. L’ajout de bruit dans le canal de communication n’est pas une idée originale, et nous la trouvons en fait dans un des premiers articles mêlant RL et émergence de communication organisée avec <span>jorge_learning_2016</span>, bien qu’ils introduisent le bruit comme une astuce de régularisation pour la convergence de leur algorithme (<em>Curriculum learning</em>), là où elle nous servira à proprement parler à influencer le langage.</p>
<p>La possibilité de donner aux agents une marge de manœuvre sur <span class="math inline"><em>B</em></span> est aussi envisageable, quoique les contours de cette expérience additionnelle devront être ajustés à la lumière des résultats de la première. Le protocole exact de cette première expérience nécessite une présentation succincte des méthodes actuellement utilisées dans l’état de l’art que nous fournissons dans la section suivante.</p>
<p>Les expériences pour tester l’apport des contraintes d’expressivité (richesse de l’environnement, contrôlable) et de concision (fonction de coût dépendant de la longueur des productions) sont faciles à intégrer à n’importe quel protocole d’expérience. La mémoire est également un facteur sur lequel nous pouvons facilement jouer puisqu’il s’agit de modifier nos modèles pour en intégrer plus ou moins. Ainsi ces paramètres seront testés sur chacune des tâches que nous développerons. Il sera en particulier intéressant d’étudier les interactions entre ces contraintes, selon le degré d’intensité que nous leur imposerons.</p>
<p>Seule la contrainte de simplicité reste non tractable… En particulier la contrainte de simplicité que nous définissons avec la complexité de Kolmogorov, définie comme la longueur minimale du programme permettant de produire la langue — dans le cas d’une langue naturelle cela équivaudrait à la taille nécessaire à la description de sa grammaire — pose de sérieux problèmes. Il est en général très dur de calculer la complexité de Kolmogorov, et l’on peut tout au plus seulement en donner des bornes inférieures dans la plupart des cas.</p>
<p>Cette contrainte est lié à la nécessité de transmettre le protocole de communication à une nouvelle génération d’agents, mais elle peut aussi être vue comme un invariant cognitif, comme suggéré par <span>chater_simplicity</span>.</p>
<p>La question de la <em>nécessité</em> de la compositionnalité dans le contexte de ces contraintes est sans doute la question centrale au travail de cette thèse. Elle nécessite l’établissement d’une définition rigoureuse et d’une compréhension profond de ses expressions. Ses manifestations peuvent être trompeuses ; prenons l’exemple de la séquentialité comme utilisation implicite de prédicats logiques. Par là nous entendons, dans le jeu de construction de Wittgenstein, la compréhension de l’énonciation consécutive de différents objets comme la nécessité de leur conjonction. C’est-à-dire que la phrase soit entendu comme le message signifiant la volonté de tous ces objets , et non de l’un d’entre eux comme ce serait le cas pour l’utilisation de la séquentialité pour le choix .</p>
<p>Détecter si une phrase fait partie d’une grammaire est un problème complexe, qui nécessite des algorithmes sophistiqués et une certaine quantité de données pour fonctionner correctement. Détecter la structure même d’une grammaire est donc un défi de taille. Plus simplement on peut citer <span>kirby_cumulative_2008</span>, qui ont introduit une mesure naïve de complexité pour tenter de deviner la naissance ou non de phénomènes de nature compositionnels en détectant les sauts de continuité pour la distance Levenstein et dans l’espace sémantique. Cette mesure est trop simpliste puisque l’existence des périphrases la rend obsolète (forte distance de Levenstein, faible distance sémantique), mais elle figure sans doute un point de départ intéressant.</p>
<p>Cette introspection sur la nature de la compositionnalité est au programme du travail de thèse. La perspective de réussir à faire émerger ce phénomène n’a rien d’évident, et il existe quelques résultats négatifs quand aux conditions de réalisations de ce phénomène, notamment <span>lake_generalization_2017</span> dans le cas d’une modélisation utilisant des réseaux de neurones classiques mais habituellement parmi les plus performants pour la modélisation du langage. Nous espérons pouvoir donner des suites à ces travaux, et dans le cas où nous ne parviendrions pas à donner naissance à de véritables systèmes compositionnels nous pourrions néanmoins simuler l’apparition de phénomènes linguistiques d’intérêt comme la phonologie ou la morphologie, qui sont des phénomènes de vocabulaire.</p>
<h1 id="formalisation-du-protocole-état-de-lart">Formalisation du protocole &amp; état de l’art</h1>
<p>Nous sommes intéressés par la façon dont des populations d’agents utilisent un ou plusieurs canaux de communication afin de résoudre une tâche partagée (collaboration) ou individualisée (compétition). Ce canal de communication peut être discrétisé, c’est le cas de la communication par symboles, ou bien continu dans le cas de la communication par vecteurs de <span class="math inline">$\mathbb R^d$</span>. Si la communication par vecteur peut fonctionner, nous nous intéresserons surtout au cas de la communication par symbole, puisque nos langages fonctionnent en discrétisant des éléments sonores et en les réassemblant pour former les mots et phrases du langage. Si la question de savoir comment nous parvenons justement à discrétiser les sons est une question active en sciences de la cognition, nous partirons simplement de l’observation de la nature foncièrement discrète du langage.</p>
<p>Le comportement des agents peut être modélisé par des algorithmes classiques, comme cela a pu être fait dans le cas de <span>kirby_cumulative_2008,steels_synthetic_1997,beuls_agent-based_2013</span> ou bien par des méthodes d’apprentissage. Nous nous intéresserons à ce dernier cas, en particulier aux agents modélisés par l’apprentissage par renforcement (RL).</p>
<h3 id="apprentissage-par-renforcement" class="unnumbered">Apprentissage par renforcement</h3>
<p>Fondamentalement le RL se base sur la théorie des jeux de Markov : <span class="math inline">(<em>S</em>,<em>A</em>,<em>P</em>,<em>R</em>)</span> avec : <span class="math inline"><em>S</em></span> un ensemble d’états fini, <span class="math inline"><em>A</em></span> un ensemble d’actions fini, <span class="math inline"><em>P</em>[<em>s</em>′ | <em>s</em>,<em>a</em>]</span> la probabilité d’être en <span class="math inline"><em>s</em>′</span> en ayant actionné <span class="math inline"><em>a</em></span> depuis l’état <span class="math inline"><em>s</em></span>, et <span class="math inline"><em>R</em>(<em>s</em>′,<em>s</em>)</span> la fonction de récompense. L’idée étant de trouver une politique <span class="math inline"><em>π</em> : <em>S</em> → <em>A</em></span> optimale qui permette de maximiser, avec <span class="math inline">0 &lt; <em>γ</em> &lt; 1</span> une préférence pour le futur, la fonction suivante, appelée fonction de valeur: <br /><span class="math display">$$V_{\pi}{\left(s\right)} = \mathbb E{\left[\sum_{t&gt;0}{\gamma^tR{\left(s_{t+1}, s_t\right)}}\ |\ s_0 = s\right]}$$</span><br /> Il existe plusieurs approches pour déterminer <span class="math inline"><em>π</em><sup>*</sup></span> la politique optimale, comme l’itération sur la politique ou sur la fonction de valeur, ou encore les estimations Monte Carlo. Cependant ces techniques ne sont envisageables que dans le cas d’espaces d’états-actions réduits. Les méthodes d’apprentissage par descente de gradient permettent de considérer des ensembles plus vastes, faisant progresser la discipline en incorporant des jeux toujours plus complexes. C’est dans cette catégorie d’algorithmes que se trouvent d’une part le célèbre AlphaGo <span class="citation"></span> et d’autre part les algorithmes qui nous intéressent dans le cas des jeux référentiels, que nous présentons maintenant.</p>
<h2 id="état-de-lart" class="unnumbered">État de l’art</h2>
<p>Le premier type de tâche qui est investigué relève des jeux de signaux ou de référence (<em>signaling games</em>, <span>lewis_convention</span>), à la façon du jeu de langage des maçons de <span>wittgenstein_philosophical_1953</span>. Dans ce contexte on cherche à plonger des agents dans un environnement simple comportant un nombre fini d’objet, ces derniers devant réussir <em>in fine</em> à se comprendre lorsqu’ils désignent l’un ou l’autre des objets de ce monde. Si ces jeux de référence ont une longue histoire et de nombreuses modélisations, un des premiers articles à employer les méthodes de RL est <span>lazaridou_multi-agent_2016</span>. Les résultats reportés par les auteurs sont encourageants, avec notamment la confirmation que des agents modélisés par des réseaux de neurones rudimentaires sont capables de se coordonner.</p>
<p>Les méthodes de RL sont difficiles à faire converger, notamment dû à une forte variance des estimateurs, et nécessitent d’impressionnantes quantités de données. Afin de pallier à ces déficiences de récents articles <span>mordatch_emergence_2017,havrylov_emergence_2017</span> ont utilisés une nouvelle méthode, l’astuce du Gumbel-Softmax, afin d’échapper à la forte variance des algorithmes dérivés de REINFORCE <span class="citation"></span>.</p>
<p>Si certains articles <span class="citation"></span> donnent des éléments encourageants quant à la capacité de faire converger les agents en leur faisant utiliser plusieurs symboles à la fois, les conclusions exactes sur la nature de ces habilités restent floues.</p>
<h2 id="protocoles-originaux" class="unnumbered">Protocoles originaux</h2>
<p>Une des pistes importantes de la thèse sera la conception de tâches complexes nécessitant l’utilisation de langages complexes pour pouvoir être surmontées. Nous sommes naturellement portés vers des jeux qui favoriseront l’émergence de mots fonctions. Le cadre exact de conception de ces jeux se situe plutôt dans le cadre de la théorie des jeux, ce qui nécessitera un travail bibliographique.</p>
<p>Une opportunité intéressante serait de faire jouer de façon conjointe des agents à un jeu portés sur la conjonction, et à un autre jeu porté sur le choix. On espèrerait ainsi forcer l’apparition de quantifieurs logiques ET, OU pour pouvoir désambiguer l’utilisation de la séquentialité. Le cadre exact de ce jeu reste à définir.</p>
<p>Un jeu intéressant est celui du labyrinthe, avec un observateur omniscient devant communiquer à un agent récepteur le chemin donnant vers la sortie. Le mode de communication optimal est évidemment séquentiel ; , mais on peut le compresser en introduisant les nombres ; . Peut-etre qu’en contraignant fortement le cout energique de communication nous pourrions forcer ce phenomene.</p>
</body>
</html>
